{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autopep8         1.5.4\n",
      "numpy            1.19.5\n",
      "json             2.0.9\n",
      "tensorflow.keras 2.4.0\n",
      "tensorflow       2.4.0\n",
      "CPython 3.7.4\n",
      "IPython 7.8.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from alibi_detect.cd import KSDrift, MMDDrift\n",
    "from alibi_detect.cd.preprocess import UAE\n",
    "from alibi_detect.models.embedding import TransformerEmbedding\n",
    "from alibi_detect.utils.saving import save_detector, load_detector\n",
    "\n",
    "# enable gpu growth if gpu is available\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "# tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "tf.config.optimizer.set_jit(True)\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -v -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load preprocessed Data from Outlier Detection Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30941, 31, 1)\n"
     ]
    }
   ],
   "source": [
    "sessions_padded = np.load('../outlier_detection/list_sessions_padded_autoencoder.npy')\n",
    "print(sessions_padded.shape)\n",
    "n_output_features = int(sessions_padded.max())\n",
    "n_unique_input_ids = int(sessions_padded.max())\n",
    "window_length = sessions_padded.shape[1]\n",
    "n_input_features = sessions_padded.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Autoencoder in functional API\n",
    "- Input: x rows (time steps) of Item IDs in a Session\n",
    "- Output: reconstructed Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_autoencoder(window_length=50,\n",
    "                      units_lstm_layer=100,\n",
    "                      n_unique_input_ids=0,\n",
    "                      embedding_dim=200,\n",
    "                      n_input_features=1,\n",
    "                      n_output_features=3,\n",
    "                      dropout_rate=0.1):\n",
    "\n",
    "    inputs = keras.layers.Input(\n",
    "        shape=[window_length, n_input_features], dtype=np.float32)\n",
    "\n",
    "    # Encoder\n",
    "    # Embedding Layer\n",
    "    embedding_layer = tf.keras.layers.Embedding(\n",
    "        n_unique_input_ids+1, embedding_dim, input_length=window_length)  # , mask_zero=True)\n",
    "    embeddings = embedding_layer(inputs[:, :, 0])\n",
    "\n",
    "    mask = inputs[:, :, 0] != 0\n",
    "\n",
    "    # LSTM Layer 1\n",
    "    lstm1_output, lstm1_state_h, lstm1_state_c = keras.layers.LSTM(units=units_lstm_layer, return_state=True,\n",
    "                                                                   return_sequences=True)(embeddings, mask=mask)\n",
    "    lstm1_state = [lstm1_state_h, lstm1_state_c]\n",
    "\n",
    "    # Decoder\n",
    "    # input: lstm1_state_c, lstm1_state_h\n",
    "    decoder_state_c = lstm1_state_c\n",
    "    decoder_state_h = lstm1_state_h\n",
    "    decoder_outputs = tf.expand_dims(lstm1_state_h, 1)\n",
    "\n",
    "    list_states = []\n",
    "    decoder_layer = keras.layers.LSTM(\n",
    "        units=units_lstm_layer, return_state=True, return_sequences=True, unroll=False)\n",
    "    for i in range(window_length):\n",
    "        decoder_outputs, decoder_state_h, decoder_state_c = decoder_layer(decoder_outputs,\n",
    "                                                                          initial_state=[decoder_state_h,\n",
    "                                                                                         decoder_state_c])\n",
    "        list_states.append(decoder_state_h)\n",
    "    stacked = tf.stack(list_states, axis=1)\n",
    "\n",
    "    fc_layer = tf.keras.layers.Dense(\n",
    "        n_output_features+1, kernel_initializer='he_normal')\n",
    "\n",
    "    fc_layer_output = tf.keras.layers.TimeDistributed(fc_layer)(\n",
    "        stacked, mask=mask)\n",
    "\n",
    "    mask_softmax = tf.tile(tf.expand_dims(mask, axis=2),\n",
    "                           [1, 1, n_output_features+1])\n",
    "\n",
    "    softmax = tf.keras.layers.Softmax(axis=2, dtype=tf.float32)(\n",
    "        fc_layer_output, mask=mask_softmax)\n",
    "\n",
    "    model = keras.models.Model(inputs=[inputs],\n",
    "                               outputs=[softmax])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concept Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2c6352d3248>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_autoencoder(window_length=window_length,\n",
    "                                             n_output_features=n_output_features,\n",
    "                                             n_unique_input_ids=n_unique_input_ids,\n",
    "                                             n_input_features=n_input_features,\n",
    "                                             embedding_dim=200,\n",
    "                                             units_lstm_layer=300,\n",
    "                                             dropout_rate=0.0)\n",
    "model.load_weights(\"../outlier_detection/weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_embedding(window_length=50,\n",
    "                          n_unique_input_ids=0,\n",
    "                          embedding_dim=200):\n",
    "    \n",
    "    inputs = keras.layers.Input(\n",
    "        shape=[window_length], dtype=np.float32)\n",
    "    \n",
    "    # Embedding Layer\n",
    "    embedding_layer = tf.keras.layers.Embedding(\n",
    "        n_unique_input_ids+1, embedding_dim, input_length=window_length)\n",
    "    embeddings = embedding_layer(inputs)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[inputs],\n",
    "                               outputs=[embeddings])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Embedding Layer from the Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 31, 200)\n"
     ]
    }
   ],
   "source": [
    "Embedding = build_embedding(window_length=window_length, n_unique_input_ids=n_unique_input_ids, embedding_dim=200)\n",
    "Embedding.layers[1].set_weights(model.layers[3].embeddings.numpy()[np.newaxis])\n",
    "\n",
    "emb = Embedding(sessions_padded[:5,:])\n",
    "print(emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = tuple(emb.shape[1:])\n",
    "enc_dim = 32\n",
    "uae = UAE(input_layer=Embedding, shape=shape, enc_dim=enc_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 32)\n"
     ]
    }
   ],
   "source": [
    "emb_uae = uae(sessions_padded[:5,:])\n",
    "print(emb_uae.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define preprocessing step parameters\n",
    "preprocess_kwargs = {\n",
    "    'model': uae,\n",
    "    'batch_size': 32\n",
    "}\n",
    "\n",
    "cd = KSDrift(\n",
    "    p_val=.05,\n",
    "    X_ref=sessions_padded,  # reference data to test against\n",
    "    preprocess_X_ref=True,  # store preprocessed X_ref for future predict calls\n",
    "    preprocess_kwargs=preprocess_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Directory ./model does not exist and is now created.\n"
     ]
    }
   ],
   "source": [
    "filepath = './model'\n",
    "save_detector(cd, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "cd = load_detector('./model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Concept Drift with some Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'is_drift': 1, 'distance': array([0.29177997, 0.34911987, 0.23460251, 0.26946124, 0.2595077 ,\n",
      "       0.4610946 , 0.36399922, 0.21240984, 0.45049787, 0.3319159 ,\n",
      "       0.29141855, 0.39273134, 0.32614478, 0.4137896 , 0.22888283,\n",
      "       0.21889608, 0.36555555, 0.62413096, 0.2220916 , 0.36459008,\n",
      "       0.21113116, 0.4130718 , 0.5817236 , 0.27963278, 0.3472668 ,\n",
      "       0.34736785, 0.24555385, 0.25989464, 0.2602046 , 0.35898882,\n",
      "       0.28831676, 0.21523486], dtype=float32), 'p_val': array([1.5688768e-08, 4.9755152e-12, 1.1508869e-05, 2.4443361e-07,\n",
      "       7.7523498e-07, 1.1465326e-20, 4.8599086e-13, 1.0127854e-04,\n",
      "       9.5294496e-20, 6.4912270e-11, 1.6430652e-08, 4.1362677e-15,\n",
      "       1.4924340e-10, 9.9915193e-17, 2.0578967e-05, 5.4849472e-05,\n",
      "       3.7890286e-13, 1.6383755e-37, 4.0272535e-05, 4.4222400e-13,\n",
      "       1.1404563e-04, 1.1379877e-16, 1.2105791e-32, 7.1848909e-08,\n",
      "       6.6023489e-12, 6.5015094e-12, 3.6341589e-06, 7.4181969e-07,\n",
      "       7.1606007e-07, 1.0752519e-12, 2.4370076e-08, 7.7713783e-05],\n",
      "      dtype=float32), 'threshold': 0.0015625}, 'meta': {'name': 'KSDrift', 'detector_type': 'offline', 'data_type': None}}\n"
     ]
    }
   ],
   "source": [
    "mask = [  169,   246,   394,   498,   630,  1039,  1578,  2008,  2040,\n",
    "         2447,  2557,  2609,  3179,  3276,  3481,  3615,  3813,  4179,\n",
    "         4361,  4794,  5077,  6184,  6369,  7347,  7596,  8415,  8761,\n",
    "         8773,  9011,  9404,  9504,  9613,  9880,  9907,  9978, 10050,\n",
    "        10229, 10573, 10654, 11196, 11429, 11477, 11493, 11654, 11975,\n",
    "        12135, 13526, 13659, 13729, 14139, 14469, 14910, 15203, 15429,\n",
    "        15934, 15982, 16310, 16352, 16504, 16647, 16743, 17046, 17085,\n",
    "        17302, 17342, 17449, 18584, 18702, 18711, 18770, 19204, 19642,\n",
    "        19758, 19863, 19891, 20135, 20244, 20652, 20865, 20899, 21077,\n",
    "        21680, 23338, 23407, 23892, 24101, 24257, 24259, 24396, 25078,\n",
    "        25127, 25380, 25576, 26071, 26082, 26123, 26323, 26373, 27007,\n",
    "        27629, 27664, 27833, 28388, 28739, 29576, 29588, 30381, 30529,\n",
    "        30873, 30930]\n",
    "preds_ood = cd.predict(sessions_padded[mask], return_p_val=True)\n",
    "print(preds_ood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Concept Drift with normal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'is_drift': 0,\n",
       "  'distance': array([0.12389968, 0.05854917, 0.09096441, 0.13766782, 0.08862545,\n",
       "         0.08763421, 0.12121715, 0.07145632, 0.07594777, 0.10657057,\n",
       "         0.093422  , 0.09063864, 0.08938367, 0.08744029, 0.09906564,\n",
       "         0.15516078, 0.09016095, 0.09892796, 0.11167997, 0.07256908,\n",
       "         0.10378947, 0.09502311, 0.11840858, 0.09213923, 0.08747099,\n",
       "         0.12627614, 0.11722504, 0.11798746, 0.06320578, 0.12884684,\n",
       "         0.07871077, 0.10619663], dtype=float32),\n",
       "  'p_val': array([0.0937343 , 0.88405776, 0.38153896, 0.04572367, 0.41401944,\n",
       "         0.42826006, 0.10685763, 0.6888091 , 0.6132912 , 0.20760556,\n",
       "         0.34917364, 0.3859664 , 0.4033153 , 0.4310781 , 0.28191262,\n",
       "         0.01646833, 0.39251527, 0.28343564, 0.16631426, 0.67012227,\n",
       "         0.2331772 , 0.32908514, 0.12219147, 0.36583787, 0.43063122,\n",
       "         0.08326028, 0.12917197, 0.124639  , 0.8207168 , 0.07305764,\n",
       "         0.5673453 , 0.2109131 ], dtype=float32),\n",
       "  'threshold': 0.0015625},\n",
       " 'meta': {'name': 'KSDrift', 'detector_type': 'offline', 'data_type': None}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_ood = cd.predict(sessions_padded[:100], return_p_val=True)\n",
    "preds_ood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
