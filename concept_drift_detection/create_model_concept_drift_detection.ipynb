{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow       2.4.0\n",
      "tensorflow.keras 2.4.0\n",
      "autopep8         1.5.4\n",
      "json             2.0.9\n",
      "numpy            1.19.5\n",
      "CPython 3.7.4\n",
      "IPython 7.8.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from alibi_detect.cd import KSDrift, MMDDrift\n",
    "from alibi_detect.cd.preprocess import UAE\n",
    "from alibi_detect.models.embedding import TransformerEmbedding\n",
    "from alibi_detect.utils.saving import save_detector, load_detector\n",
    "\n",
    "# Disable GPU\n",
    "tf.config.experimental.set_visible_devices([], 'GPU')\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -v -iv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load preprocessed Data from Outlier Detection Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45916, 207, 1)\n"
     ]
    }
   ],
   "source": [
    "sessions_padded = np.load('../outlier_detection/list_sessions_padded_autoencoder.npy')\n",
    "print(sessions_padded.shape)\n",
    "n_output_features = int(sessions_padded.max())\n",
    "n_unique_input_ids = int(sessions_padded.max())\n",
    "window_length = sessions_padded.shape[1]\n",
    "n_input_features = sessions_padded.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Autoencoder in functional API\n",
    "- Input: x rows (time steps) of Item IDs in a Session\n",
    "- Output: reconstructed Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_autoencoder(window_length=50,\n",
    "                      units_lstm_layer=100,\n",
    "                      n_unique_input_ids=0,\n",
    "                      embedding_dim=200,\n",
    "                      n_input_features=1,\n",
    "                      n_output_features=3,\n",
    "                      dropout_rate=0.1):\n",
    "\n",
    "    inputs = keras.layers.Input(\n",
    "        shape=[window_length, n_input_features], dtype=np.float32)\n",
    "\n",
    "    # Encoder\n",
    "    # Embedding Layer\n",
    "    embedding_layer = tf.keras.layers.Embedding(\n",
    "        n_unique_input_ids+1, embedding_dim, input_length=window_length)  # , mask_zero=True)\n",
    "    embeddings = embedding_layer(inputs[:, :, 0])\n",
    "\n",
    "    mask = inputs[:, :, 0] != 0\n",
    "\n",
    "    # LSTM Layer 1\n",
    "    lstm1_output, lstm1_state_h, lstm1_state_c = keras.layers.LSTM(units=units_lstm_layer, return_state=True,\n",
    "                                                                   return_sequences=True)(embeddings, mask=mask)\n",
    "    lstm1_state = [lstm1_state_h, lstm1_state_c]\n",
    "\n",
    "    # Decoder\n",
    "    # input: lstm1_state_c, lstm1_state_h\n",
    "    decoder_state_c = lstm1_state_c\n",
    "    decoder_state_h = lstm1_state_h\n",
    "    decoder_outputs = tf.expand_dims(lstm1_state_h, 1)\n",
    "\n",
    "    list_states = []\n",
    "    decoder_layer = keras.layers.LSTM(\n",
    "        units=units_lstm_layer, return_state=True, return_sequences=True, unroll=False)\n",
    "    for i in range(window_length):\n",
    "        decoder_outputs, decoder_state_h, decoder_state_c = decoder_layer(decoder_outputs,\n",
    "                                                                          initial_state=[decoder_state_h,\n",
    "                                                                                         decoder_state_c])\n",
    "        list_states.append(decoder_state_h)\n",
    "    stacked = tf.stack(list_states, axis=1)\n",
    "\n",
    "    fc_layer = tf.keras.layers.Dense(\n",
    "        n_output_features+1, kernel_initializer='he_normal', dtype=tf.float32)\n",
    "\n",
    "    fc_layer_output = tf.keras.layers.TimeDistributed(fc_layer)(\n",
    "        stacked, mask=mask)\n",
    "\n",
    "    mask_softmax = tf.tile(tf.expand_dims(mask, axis=2),\n",
    "                           [1, 1, n_output_features+1])\n",
    "\n",
    "    softmax = tf.keras.layers.Softmax(axis=2)(\n",
    "        fc_layer_output, mask=mask_softmax)\n",
    "\n",
    "    model = keras.models.Model(inputs=[inputs],\n",
    "                               outputs=[softmax])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concept Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2b715f50108>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_autoencoder(window_length=window_length,\n",
    "                                             n_output_features=n_output_features,\n",
    "                                             n_unique_input_ids=n_unique_input_ids,\n",
    "                                             n_input_features=n_input_features,\n",
    "                                             embedding_dim=200,\n",
    "                                             units_lstm_layer=500,\n",
    "                                             dropout_rate=0.0)\n",
    "model.load_weights(\"../outlier_detection/weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_embedding(window_length=50,\n",
    "                          n_unique_input_ids=0,\n",
    "                          embedding_dim=200):\n",
    "    \n",
    "    inputs = keras.layers.Input(\n",
    "        shape=[window_length], dtype=np.float32)\n",
    "    \n",
    "    # Embedding Layer\n",
    "    embedding_layer = tf.keras.layers.Embedding(\n",
    "        n_unique_input_ids+1, embedding_dim, input_length=window_length)\n",
    "    embeddings = embedding_layer(inputs)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[inputs],\n",
    "                               outputs=[embeddings])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Embedding Layer from the Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 207, 200)\n"
     ]
    }
   ],
   "source": [
    "Embedding = build_embedding(window_length=window_length, n_unique_input_ids=n_unique_input_ids, embedding_dim=200)\n",
    "Embedding.layers[1].set_weights(model.layers[3].embeddings.numpy()[np.newaxis])\n",
    "\n",
    "emb = Embedding(sessions_padded[:5,:])\n",
    "print(emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = tuple(emb.shape[1:])\n",
    "enc_dim = 32\n",
    "uae = UAE(input_layer=Embedding, shape=shape, enc_dim=enc_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 32)\n"
     ]
    }
   ],
   "source": [
    "emb_uae = uae(sessions_padded[:5,:])\n",
    "print(emb_uae.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define preprocessing step parameters\n",
    "preprocess_kwargs = {\n",
    "    'model': uae,\n",
    "    'batch_size': 32\n",
    "}\n",
    "\n",
    "cd = KSDrift(\n",
    "    p_val=.05,\n",
    "    X_ref=sessions_padded,  # reference data to test against\n",
    "    preprocess_X_ref=True,  # store preprocessed X_ref for future predict calls\n",
    "    preprocess_kwargs=preprocess_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Directory ./model does not exist and is now created.\n"
     ]
    }
   ],
   "source": [
    "filepath = './model'\n",
    "save_detector(cd, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "cd = load_detector('./model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Concept Drift with some Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'is_drift': 1, 'distance': array([0.368352  , 0.37975392, 0.41268158, 0.36084983, 0.36416024,\n",
      "       0.40482894, 0.37353265, 0.20875213, 0.4468486 , 0.30124167,\n",
      "       0.3088915 , 0.38088983, 0.2658605 , 0.30052364, 0.2464582 ,\n",
      "       0.30943325, 0.45181417, 0.27487695, 0.22882342, 0.3953136 ,\n",
      "       0.35303393, 0.41076162, 0.2986847 , 0.25553048, 0.29826817,\n",
      "       0.43733734, 0.47010234, 0.44312507, 0.34793565, 0.3328524 ,\n",
      "       0.35619256, 0.3159547 ], dtype=float32), 'p_val': array([1.8104736e-15, 2.0515612e-16, 2.6250678e-19, 7.3167350e-15,\n",
      "       3.9647977e-15, 1.3517198e-18, 6.7868425e-16, 2.9483872e-05,\n",
      "       1.4559551e-22, 1.7375296e-10, 5.2778108e-11, 1.6454715e-16,\n",
      "       2.9141837e-08, 1.9401585e-10, 3.6862471e-07, 4.8452339e-11,\n",
      "       4.6601658e-23, 8.3939096e-09, 3.1321515e-06, 9.4408654e-18,\n",
      "       3.0404265e-14, 3.9302737e-19, 2.5704383e-10, 1.1525539e-07,\n",
      "       2.7388886e-10, 1.2460515e-21, 6.2966769e-25, 3.3927592e-22,\n",
      "       7.5710820e-14, 1.0414281e-12, 1.7161895e-14, 1.7105642e-11],\n",
      "      dtype=float32), 'threshold': 0.0015625}, 'meta': {'name': 'KSDrift', 'detector_type': 'offline', 'data_type': None}}\n"
     ]
    }
   ],
   "source": [
    "mask = [  805,   850,  1410,  2065,  2463,  2728,  3525,  5037,  5906,\n",
    "         5959,  5994,  6639,  6757,  7137,  7613,  7637,  7931,  8398,\n",
    "         9452, 10298, 11209, 11436, 11574, 11735, 11755, 11865, 12416,\n",
    "        12735, 13061, 13148, 13352, 13369, 13544, 13642, 14233, 14356,\n",
    "        15380, 15739, 16186, 16409, 16581, 17275, 17350, 17767, 17960,\n",
    "        18187, 18660, 19081, 19269, 19434, 19523, 19675, 20483, 20539,\n",
    "        20595, 20604, 21410, 21713, 22416, 22695, 22991, 23023, 23994,\n",
    "        24052, 24197, 24208, 24325, 24815, 24871, 25030, 25057, 25168,\n",
    "        25280, 25825, 26030, 26401, 26616, 27054, 27153, 27426, 27679,\n",
    "        30020, 30425, 30791, 30847, 30876, 31115, 31220, 32672, 32730,\n",
    "        32753, 33017, 33074, 33152, 33183, 33850, 34458, 35150, 35686,\n",
    "        36259, 36321, 37746, 37820, 37972, 38047, 38311, 38568, 38627,\n",
    "        38833, 38974, 39236, 39910, 40448, 40558, 40634, 40979, 41124,\n",
    "        41239, 41592, 41968, 42151, 42347, 42727, 42959, 43899, 44101,\n",
    "        44613, 45188]\n",
    "preds_ood = cd.predict(sessions_padded[mask], return_p_val=True)\n",
    "print(preds_ood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Concept Drift with normal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'is_drift': 0,\n",
       "  'distance': array([0.10480443, 0.08111247, 0.07187386, 0.08680809, 0.07404129,\n",
       "         0.05961843, 0.05158376, 0.0735639 , 0.06709905, 0.09586114,\n",
       "         0.04634114, 0.0570372 , 0.08720359, 0.10140082, 0.06235909,\n",
       "         0.08118738, 0.07082412, 0.10679328, 0.07208642, 0.09112292,\n",
       "         0.07191916, 0.10646659, 0.04683335, 0.09178151, 0.12237477,\n",
       "         0.06620698, 0.08474606, 0.05472515, 0.0566295 , 0.0677228 ,\n",
       "         0.09936493, 0.07004704], dtype=float32),\n",
       "  'p_val': array([0.22307067, 0.5275708 , 0.6811714 , 0.43966496, 0.6446806 ,\n",
       "         0.87013763, 0.9533246 , 0.6527243 , 0.759998  , 0.3182817 ,\n",
       "         0.9828912 , 0.90162665, 0.4338617 , 0.2564216 , 0.8325692 ,\n",
       "         0.52636766, 0.69876456, 0.2051651 , 0.67759955, 0.3787502 ,\n",
       "         0.68041044, 0.20802791, 0.98090535, 0.3699333 , 0.1007021 ,\n",
       "         0.7742269 , 0.4705918 , 0.926135  , 0.90621316, 0.74992853,\n",
       "         0.2780507 , 0.71171975], dtype=float32),\n",
       "  'threshold': 0.0015625},\n",
       " 'meta': {'name': 'KSDrift', 'detector_type': 'offline', 'data_type': None}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_ood = cd.predict(sessions_padded[:100], return_p_val=True)\n",
    "preds_ood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
